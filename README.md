"""
prompt_constructor.py
---------------------
This module constructs and validates structured prompts
for LLM-based systems. It ensures each prompt is complete,
safe, and ready for model consumption.
"""

import re
import logging
from datetime import datetime


#  CONFIGURATION

MAX_PROMPT_LENGTH = 2000
BANNED_TERMS = [
    "password", "api_key", "token", "ignore previous",
    "execute shell", "system override", "sudo", "delete all",
]
REQUIRED_SECTIONS = ["Context", "Task"]

# Logging setup
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)


#  CUSTOM ERROR CLASS
class PromptValidationError(Exception):
    """Raised when the constructed prompt fails validation."""
    pass


#  PROMPT CONSTRUCTOR CLASS

class PromptConstructor:
    """
    Builds a clean, safe, and structured LLM prompt.
    Validates essential sections and checks safety rules.
    """

    def __init__(self, max_length: int = MAX_PROMPT_LENGTH):
        self.max_length = max_length

    
    # Core Method: Build Prompt
    
    def build_prompt(
        self,
        context: str,
        task: str,
        input_example: str = None,
        expected_output: str = None
    ) -> str:
        """
        Combine user inputs into a standard, well-structured prompt.
        """
        logger.info("Building prompt...")

        parts = [
            f"Context: {context.strip()}",
            f"Task: {task.strip()}",
        ]

        if input_example:
            parts.append(f"Input Example: {input_example.strip()}")
        if expected_output:
            parts.append(f"Expected Output: {expected_output.strip()}")

        full_prompt = "\n\n".join(parts)
        logger.info("Prompt constructed successfully.")
        self.validate_prompt(full_prompt)

        return full_prompt

    # Prompt Validation Logic
    
    def validate_prompt(self, prompt: str) -> None:
        """
        Validates completeness, safety, and structure of the prompt.
        """
        logger.info("Validating constructed prompt...")

        # 1️ Check for required sections
        for section in REQUIRED_SECTIONS:
            if not re.search(rf"^{section}:", prompt, flags=re.MULTILINE):
                raise PromptValidationError(f"Missing required section: {section}")

        # 2️  Length check
        if len(prompt) > self.max_length:
            raise PromptValidationError(
                f"Prompt exceeds maximum allowed length ({self.max_length} chars)"
            )

        # 3️ Banned terms check
        for term in BANNED_TERMS:
            if re.search(rf"\b{re.escape(term)}\b", prompt, re.IGNORECASE):
                raise PromptValidationError(
                    f"Unsafe or banned term detected: '{term}'"
                )

        # 4️ Injection pattern detection
        injection_patterns = [
            r"ignore\s+previous\s+instructions",
            r"system\s*override",
            r"execute\s*command",
            r"delete\s+all\s+files",
        ]
        for pattern in injection_patterns:
            if re.search(pattern, prompt, re.IGNORECASE):
                raise PromptValidationError(
                    f"Prompt contains unsafe instruction pattern: {pattern}"
                )

        # 5️ Empty section or vague instruction detection
        if re.search(r":\s*$", prompt, re.MULTILINE):
            raise PromptValidationError("One of the sections appears empty.")

        # 6️ Grammar/Vagueness check (simple heuristic)
        if re.search(r"\betc\b|\bdo something\b", prompt, re.IGNORECASE):
            raise PromptValidationError("Prompt too vague. Be more specific.")

        logger.info("Prompt validation successful.")


#  MAIN EXECUTION (Example)

if __name__ == "__main__":
    try:
        constructor = PromptConstructor()

        # Example use case (Failure Categorization)
        prompt = constructor.build_prompt(
            context=(
                "The system analyzes log data generated by test case executions "
                "to identify and categorize failure causes. Each log may include "
                "error codes, messages, or stack traces."
            ),
            task=(
                "Classify the given log as one of the following categories: "
                "Environment Issue, Application Issue, or Code Error. "
                "Provide reasoning for your classification."
            ),
            input_example="Error: Connection timeout while accessing database.",
            expected_output=(
                "Category: Environment Issue\n"
                "Reason: Network connectivity failure prevented database access."
            )
        )

        print("\n Constructed Prompt:\n")
        print(prompt)
        print("\n Prompt successfully built and validated for LLM use.")

    except PromptValidationError as e:
        print(f"\n Prompt validation failed: {e}")
    except Exception as e:
        print(f"\n Unexpected error: {e}")
